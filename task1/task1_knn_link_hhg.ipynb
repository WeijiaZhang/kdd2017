{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from datetime import datetime, timedelta, time, date\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#using KNN to predict\n",
    "train_path_1 = '../dataset/training/trajectories(table 5)_training.csv'\n",
    "train_path_2 = '../dataset/dataSet_phase2/trajectories(table_5)_training2.csv'\n",
    "test_path = '../dataset/dataSet_phase2/trajectories(table 5)_test2.csv'\n",
    "\n",
    "train_df_1 = pd.read_csv(train_path_1)\n",
    "train_df_2 = pd.read_csv(train_path_2)\n",
    "train_df = train_df_1.append(train_df_2, ignore_index=True)\n",
    "\n",
    "test_df = pd.read_csv(test_path)\n",
    "train_df.starting_time = pd.to_datetime(train_df.starting_time)\n",
    "test_df.starting_time = pd.to_datetime(test_df.starting_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from 9-19 to 10-17 (except holiday)\n",
    "NUM_TRAIN_DAYS = 20\n",
    "\n",
    "# from 10-18 to 10-24\n",
    "NUM_TSET_DAYS = 7\n",
    "\n",
    "# define Holiday\n",
    "NATIONNAL_START = date(2016,10,1)\n",
    "NATIONNAL_END = date(2016,10,9)\n",
    "\n",
    "MID_AUTUMN_START = date(2016,9,15)\n",
    "MID_AUTUMN_END = date(2016,9,18)\n",
    "\n",
    "TRAIN_START_DAY = date(2016,7,19)\n",
    "#TRAIN_START_DAY = date(2016,10,10)\n",
    "TRAIN_END_DAY = date(2016,10,24)\n",
    "\n",
    "VALI_START_DAY = date(2016,10,18)\n",
    "VALI_END_DAY = date(2016,10,24)\n",
    "\n",
    "TEST_START_DAY = date(2016,10,25)\n",
    "TEST_END_DAY = date(2016,10,31)\n",
    "\n",
    "# 每条路劲的link\n",
    "LINK_A_2 = [110,123,107,108,120,117]\n",
    "LINK_A_3 = [110,123,107,108,119,114,118,122]\n",
    "LINK_B_1 = [105,100,111,103,116,101,121,106,113]\n",
    "LINK_B_3 = [105,100,111,103,122]\n",
    "LINK_C_1 = [115,102,109,104,112,111,103,116,101,121,106,113]\n",
    "LINK_C_3 = [115,102,109,104,112,111,103,122]\n",
    "\n",
    "#每条路的link个数\n",
    "LINK_LENGTH = {'table_A_2':6, 'table_A_3':8,'table_B_1':9,'table_B_3':5,'table_C_1':12,'table_C_3':8}               \n",
    "# LINK_LENGTH = {'table_C_3':8}\n",
    "\n",
    "inter_toll = [('A',2), ('A',3), ('B',1), ('B',3), ('C',1), ('C',3)]\n",
    "# inter_toll = [('C',3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MAPE(pred, true):\n",
    "    return abs((true - pred) / true)\n",
    "\n",
    "def cal_mape(pred_values, true_values):\n",
    "    mape_mean = 0.0\n",
    "    for i in range(len(pred_values)):\n",
    "        pred_i = pred_values[i]\n",
    "        true_i = true_values[i]\n",
    "        mape_mean += abs((pred_i-true_i) / true_i)\n",
    "    mape_mean /= len(pred_values)\n",
    "    return mape_mean\n",
    "\n",
    "def per_20min(dt):\n",
    "    minute = int(math.floor(dt.minute / 20) * 20)\n",
    "    second = 0\n",
    "    dt_new = datetime(dt.year, dt.month, dt.day, dt.hour,minute, 0)\n",
    "    return dt_new\n",
    "\n",
    "# 9~19～10.17只有国庆节，因此只考虑国庆节\n",
    "def remove_holiday(df):\n",
    "    day_all = df.starting_time.dt.date\n",
    "    df = df.loc[((day_all < MID_AUTUMN_START) | (day_all > MID_AUTUMN_END))]\n",
    "    df = df.loc[((day_all < NATIONNAL_START) | (day_all > NATIONNAL_END))]\n",
    "    return df\n",
    "\n",
    "\n",
    "def slice_am_pm(df):\n",
    "    hours = df.starting_time.dt.hour\n",
    "    df_am = df.loc[(hours < 12)]\n",
    "    df_pm = df.loc[(hours >= 12)]\n",
    "    return df_am, df_pm\n",
    "\n",
    "def slice_time(df):\n",
    "    hour = df.starting_time.dt.hour  \n",
    "    df_prev2h = df.loc[(((hour >= 6) & (hour < 8)) | ((hour >= 15) & (hour < 17)))]\n",
    "    df_follow2h = df.loc[(((hour >= 8) & (hour < 10)) | ((hour >= 17) & (hour < 19)))]\n",
    "    return df_prev2h, df_follow2h\n",
    "\n",
    "\n",
    "def select_time(df):\n",
    "    df['starting_time'] = df.starting_time.apply(\n",
    "        per_20min)\n",
    "    if {'vehicle_id','travel_seq'}.issubset(df.columns):\n",
    "        df = df.drop(['vehicle_id','travel_seq'], axis=1)\n",
    "    df = df.groupby(['intersection_id', 'tollgate_id', 'starting_time']).mean()\n",
    "    df = df.reset_index()\n",
    "    df = df.rename_axis({'travel_time':'avg_travel_time'}, axis='columns')\n",
    "    hour = df.starting_time.dt.hour\n",
    "    df = df.loc[((hour >= 6) & (hour < 10)) \n",
    "                     | ((hour >= 15) & (hour < 19))]\n",
    "    return df\n",
    "\n",
    "#创建6个表,把df数据按inter_toll分成6份放进set_table\n",
    "def createTable(df): \n",
    "    set_table_fun = {}\n",
    "    for i in range(len(inter_toll)):\n",
    "        inter, toll = inter_toll[i]\n",
    "        table_name = 'table_'+str(inter)+'_'+str(toll)\n",
    "        set_table_fun[str(table_name)] = df.loc[(df.intersection_id == inter) & (df.tollgate_id == toll)]\n",
    "    return set_table_fun\n",
    "\n",
    "def getLink_avgTime(ser):  #ser是Series\n",
    "    str_travel_seq = ser.split(';')\n",
    "    link_time = []\n",
    "    for i in range(len(str_travel_seq)):\n",
    "        link_time.append(str_travel_seq[i].split('#')[-1])\n",
    "    return link_time\n",
    "\n",
    "def split_table(tableName, inter, toll, df):\n",
    "    for i in range(LINK_LENGTH[tableName]):\n",
    "        #把n列LINK添加到set_table_fun_new末尾\n",
    "        link_name = 'link_'+str(i)\n",
    "        \n",
    "        #预处理数据，把有link路段的时间缺省的数据剔除\n",
    "        judgeIndex = df.travel_seq.apply(lambda t:True if len(t)==LINK_LENGTH[tableName] else False)\n",
    "        df = df.loc[judgeIndex]\n",
    "        \n",
    "        #分列\n",
    "        df[str(link_name)] = df.travel_seq.apply(lambda s:float(s[i]))\n",
    "    return df\n",
    "        \n",
    "\n",
    "def select_time_in_link(df):   #link级别的时间处理。最后分6个表来返回\n",
    "    df['starting_time'] = df.starting_time.apply(\n",
    "        per_20min)\n",
    "    if {'vehicle_id','travel_time'}.issubset(df.columns):\n",
    "        df = df.drop(['vehicle_id','travel_time'], axis=1)\n",
    "    #set_table = pd.DataFrame(columns = ['table_A_2','table_A_3','table_B_1','table_B_3','table_C_1','table_C_3'])\n",
    "    set_table_fun = {}\n",
    "    set_table_fun = createTable(df)   #数据按inter_toll分成6份\n",
    "    #处理travel_seq,把每个link的时间取出来\n",
    "    for i in range(len(inter_toll)):\n",
    "        inter, toll = inter_toll[i]\n",
    "        tableName = 'table_'+str(inter)+'_'+str(toll)\n",
    "        set_table_fun[tableName].travel_seq = set_table_fun[tableName].travel_seq.apply(getLink_avgTime)\n",
    "        hour = set_table_fun[tableName].starting_time.dt.hour\n",
    "        set_table_fun[tableName] = set_table_fun[tableName].loc[((hour >= 6) & (hour < 10)) |\\\n",
    "                                                                ((hour >= 15) & (hour < 19))]\n",
    "        \n",
    "        #暂时只取9.19之后\n",
    "        d = set_table_fun[tableName].starting_time.dt.date\n",
    "        set_table_fun[tableName] = set_table_fun[tableName].loc[(d >= TRAIN_START_DAY) &\\\n",
    "                                                                (d <= TRAIN_END_DAY)]\n",
    "        \n",
    "        #print(set_table_fun[tableName])\n",
    "        #把set_table_fun的travel_seq拆分成n列的link\n",
    "        set_table_fun[tableName] = split_table(tableName, inter, toll, set_table_fun[tableName])\n",
    "        #去掉travel_seq\n",
    "        set_table_fun[tableName] = set_table_fun[tableName].drop(['travel_seq'],axis=1)\n",
    "    return set_table_fun\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py:2773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理，分别是训练集，验证集和测试集\n",
    "train_df = remove_holiday(train_df)\n",
    "\n",
    "#先按路径来分组，接着处理travel_seq字符串；然后把travel_seq拆分成n个link列\n",
    "set_table_dict = select_time_in_link(train_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       intersection_id  tollgate_id       starting_time  link_0  link_1  \\\n",
      "92                   C            3 2016-07-19 06:20:00    8.34   10.11   \n",
      "118                  C            3 2016-07-19 06:40:00    8.67    8.08   \n",
      "137                  C            3 2016-07-19 07:00:00    4.75    5.81   \n",
      "155                  C            3 2016-07-19 07:20:00    7.30    7.70   \n",
      "190                  C            3 2016-07-19 08:00:00    6.14    7.52   \n",
      "209                  C            3 2016-07-19 08:20:00    9.62   10.85   \n",
      "315                  C            3 2016-07-19 09:40:00    8.33    7.99   \n",
      "686                  C            3 2016-07-19 15:00:00   10.54    9.63   \n",
      "708                  C            3 2016-07-19 15:20:00    9.45    9.18   \n",
      "712                  C            3 2016-07-19 15:20:00   10.87   11.26   \n",
      "718                  C            3 2016-07-19 15:20:00    9.46    8.87   \n",
      "763                  C            3 2016-07-19 16:00:00    9.80   12.07   \n",
      "778                  C            3 2016-07-19 16:00:00   11.64   12.88   \n",
      "788                  C            3 2016-07-19 16:20:00    9.41    9.43   \n",
      "796                  C            3 2016-07-19 16:20:00    9.68    9.10   \n",
      "799                  C            3 2016-07-19 16:20:00    9.43   10.38   \n",
      "808                  C            3 2016-07-19 16:40:00   10.31    8.99   \n",
      "841                  C            3 2016-07-19 17:00:00    6.59    6.66   \n",
      "850                  C            3 2016-07-19 17:20:00    8.56   10.48   \n",
      "859                  C            3 2016-07-19 17:20:00    8.68   10.43   \n",
      "865                  C            3 2016-07-19 17:20:00    9.74    9.41   \n",
      "873                  C            3 2016-07-19 17:40:00   10.00    8.98   \n",
      "904                  C            3 2016-07-19 18:00:00    6.18    8.25   \n",
      "914                  C            3 2016-07-19 18:20:00    9.35   10.19   \n",
      "917                  C            3 2016-07-19 18:20:00   14.91   11.91   \n",
      "919                  C            3 2016-07-19 18:20:00   15.41   11.14   \n",
      "940                  C            3 2016-07-19 18:40:00   11.04   11.61   \n",
      "1235                 C            3 2016-07-20 07:00:00   38.58    9.97   \n",
      "1240                 C            3 2016-07-20 07:20:00   12.21   14.95   \n",
      "1245                 C            3 2016-07-20 07:20:00   11.10   12.54   \n",
      "...                ...          ...                 ...     ...     ...   \n",
      "118136               C            3 2016-10-24 07:00:00    4.75    5.81   \n",
      "118263               C            3 2016-10-24 08:40:00    8.66    9.14   \n",
      "118277               C            3 2016-10-24 08:40:00    7.62   10.65   \n",
      "118334               C            3 2016-10-24 09:20:00   28.91    7.68   \n",
      "118376               C            3 2016-10-24 09:40:00    9.86   11.52   \n",
      "118379               C            3 2016-10-24 09:40:00   11.04   13.52   \n",
      "118892               C            3 2016-10-24 15:00:00   39.25   12.61   \n",
      "118894               C            3 2016-10-24 15:00:00   15.25   11.04   \n",
      "118895               C            3 2016-10-24 15:00:00    8.85   10.48   \n",
      "118897               C            3 2016-10-24 15:00:00    6.90    9.03   \n",
      "118918               C            3 2016-10-24 15:20:00    9.91   10.00   \n",
      "118945               C            3 2016-10-24 15:20:00   11.07   11.08   \n",
      "118949               C            3 2016-10-24 15:40:00    8.12    8.96   \n",
      "118962               C            3 2016-10-24 15:40:00    7.93   10.13   \n",
      "118978               C            3 2016-10-24 15:40:00    7.95    9.73   \n",
      "118981               C            3 2016-10-24 15:40:00   15.00   11.66   \n",
      "118997               C            3 2016-10-24 16:00:00   11.58   10.26   \n",
      "119003               C            3 2016-10-24 16:00:00   10.49   11.35   \n",
      "119005               C            3 2016-10-24 16:00:00    8.84    9.83   \n",
      "119047               C            3 2016-10-24 16:40:00    9.60   11.08   \n",
      "119052               C            3 2016-10-24 16:40:00    8.28    7.57   \n",
      "119056               C            3 2016-10-24 16:40:00   39.54    6.73   \n",
      "119069               C            3 2016-10-24 17:00:00    7.79   10.64   \n",
      "119092               C            3 2016-10-24 17:00:00    9.16    9.76   \n",
      "119108               C            3 2016-10-24 17:20:00    9.38   10.14   \n",
      "119117               C            3 2016-10-24 17:20:00    9.65   12.97   \n",
      "119120               C            3 2016-10-24 17:20:00   12.80   12.90   \n",
      "119128               C            3 2016-10-24 17:20:00   16.05   11.17   \n",
      "119136               C            3 2016-10-24 17:40:00    8.44    7.55   \n",
      "119195               C            3 2016-10-24 18:20:00    8.32    9.83   \n",
      "\n",
      "        link_2  link_3  link_4  link_5  link_6  link_7  \n",
      "92        9.90   22.04   18.81   14.52    3.38   71.74  \n",
      "118       7.49   16.44   15.97  141.36    0.98   24.81  \n",
      "137       5.99   12.99    8.82   85.33    1.16    9.92  \n",
      "155       9.32   26.23   57.27   94.40    2.63   30.12  \n",
      "190      13.99   32.32   21.95   13.35    2.54   21.73  \n",
      "209      10.79   23.42   16.34   33.33    6.85   30.37  \n",
      "315       7.68   21.03   14.09   51.66    1.99   25.70  \n",
      "686       9.01   20.18   17.18   57.73    1.81   29.10  \n",
      "708      10.07   30.22   50.04   17.40   78.40   24.48  \n",
      "712      10.84   26.59   55.95   71.38    2.07   27.72  \n",
      "718       7.37   22.43   19.80   12.45    7.14   18.32  \n",
      "763      12.15   28.34   18.47   87.16    3.86   23.52  \n",
      "778      10.89   33.75   35.98   21.88    4.16   35.62  \n",
      "788       8.98   22.01   17.36   20.89   18.80   80.98  \n",
      "796       8.89   45.25   21.53   52.41    8.00  122.64  \n",
      "799      14.09   45.22   42.62   44.67    2.21   92.93  \n",
      "808       8.92   20.69   14.64   10.79    2.08   18.50  \n",
      "841       6.37   15.86   12.76   16.18    1.73   32.09  \n",
      "850      10.68   16.28   13.10   92.40    1.44   22.40  \n",
      "859      10.64   18.88   15.56   53.74    1.54   24.67  \n",
      "865       9.42   25.57   68.67   25.81    3.22   42.27  \n",
      "873       7.88   23.35   72.62   46.52    1.12   31.77  \n",
      "904       8.19   40.75   24.14   15.90    6.93   22.43  \n",
      "914       8.66   19.44   66.60   15.41    2.25   43.69  \n",
      "917      10.29   33.56  107.31  105.48    2.77   29.12  \n",
      "919      10.08   22.87   62.53  117.98    1.73   24.23  \n",
      "940      11.97   25.36   67.80   11.57    2.70   32.96  \n",
      "1235     10.28   41.32   33.17   20.17    5.02   59.97  \n",
      "1240     15.41   33.44   22.71   13.81    2.63   22.49  \n",
      "1245     12.81   27.81   18.88   51.61    2.65  571.09  \n",
      "...        ...     ...     ...     ...     ...     ...  \n",
      "118136    5.99   18.33   16.50   28.41    2.90   28.56  \n",
      "118263    9.22   25.77   18.03   11.00    2.36   22.45  \n",
      "118277   12.45   30.00   52.70   20.77    3.95   33.82  \n",
      "118334    7.87   21.26   15.82   28.32    6.45   25.25  \n",
      "118376   10.92   26.42   17.94   10.91    2.07   17.76  \n",
      "118379   11.73   27.97   57.45   87.43    2.07   17.77  \n",
      "118892   12.99   28.20   19.16   11.65    5.22   72.85  \n",
      "118894   11.38   25.13   21.70   15.50   62.86   23.74  \n",
      "118895    8.60   21.64   16.99   66.16    5.69   34.97  \n",
      "118897    9.09   23.44   59.12   18.56    6.43   25.70  \n",
      "118918   11.27   25.45   19.19   14.00    2.38   20.41  \n",
      "118945   11.70   21.62   19.20   13.10   35.79   46.94  \n",
      "118949    8.50   21.66   62.55   52.35    2.59   22.20  \n",
      "118962   10.44   22.65   15.39    9.36    1.78   15.23  \n",
      "118978   10.31   22.66   90.06   45.31    1.90   64.73  \n",
      "118981    9.07   20.95   17.67   45.95    7.01   52.28  \n",
      "118997    8.54   20.95   16.94   85.22    5.11   23.11  \n",
      "119003   10.17   27.24   27.31   22.17    4.21   47.00  \n",
      "119005    9.70   21.70   20.36   29.61    2.60   25.99  \n",
      "119047   11.01   23.61   18.33   27.60    1.99   26.71  \n",
      "119052    8.21   21.52   17.24   13.19    7.28   47.80  \n",
      "119056    7.08   21.64   22.72   60.84    3.30   50.92  \n",
      "119069   12.20   24.67   68.73   44.65    2.51   21.52  \n",
      "119092    9.52   23.65   17.45   17.11    1.27   40.06  \n",
      "119108   11.21   28.61   73.73   37.24    3.20   81.10  \n",
      "119117   10.05   30.22   24.40   16.11    9.03   38.76  \n",
      "119120   10.02   23.61   19.11   11.62    2.21   19.31  \n",
      "119128    9.17   24.69   20.63   24.58    1.30   29.29  \n",
      "119136    7.15   17.89   14.53   13.20   24.90   16.53  \n",
      "119195    8.92   22.65   21.26   12.13    2.44   22.12  \n",
      "\n",
      "[1832 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(set_table_dict['table_C_3'])  #每个link的travel_time获取正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complete_miss_time(df, inter, toll, linkname, df_type='train'):\n",
    "    start_day = df.starting_time.dt.date.values[0]\n",
    "    end_day = df.starting_time.dt.date.values[-1]\n",
    "\n",
    "    if df_type == 'test':\n",
    "        hour_min = [(6,0), (6,20), (6,40), (7,0), (7,20), (7,40),\n",
    "              (15,0), (15,20), (15,40), (16,0), (16,20), (16,40)] \n",
    "    else:        \n",
    "        hour_min = [(6,0), (6,20), (6,40), (7,0), (7,20), (7,40),\n",
    "                (8,0), (8,20), (8,40), (9,0), (9,20), (9,40),\n",
    "              (15,0), (15,20), (15,40), (16,0), (16,20), (16,40),\n",
    "              (17,0), (17,20), (17,40), (18,0), (18,20), (18,40)]\n",
    "    df_comp = pd.DataFrame(columns=['intersection_id', 'tollgate_id',\n",
    "                                    'starting_time',linkname])\n",
    "    for d in range((end_day - start_day).days+1):\n",
    "        day = start_day + timedelta(days=d)\n",
    "        if ((day < NATIONNAL_START) or (day > NATIONNAL_END)):\n",
    "            for j in range(len(hour_min)):\n",
    "                h, m = hour_min[j]\n",
    "                day_time = datetime(day.year, day.month, day.day, h, m, 0)\n",
    "                index = (df.starting_time == day_time)\n",
    "                avg_travel_time = df.loc[index][linkname]\n",
    "                if (not avg_travel_time.empty):\n",
    "                    avg = avg_travel_time.values[0]\n",
    "                else:\n",
    "                    avg = np.NaN\n",
    "                row = {'intersection_id': inter, 'tollgate_id': toll,\n",
    "                       'starting_time': str(day_time), linkname:avg} \n",
    "                df_comp = df_comp.append(row, ignore_index=True)\n",
    "    \n",
    "    df_comp['tollgate_id'] = df_comp['tollgate_id'].astype(int)\n",
    "    df_comp.starting_time = pd.to_datetime(df_comp.starting_time)\n",
    "    df_comp[linkname] = df_comp[linkname].interpolate()   #使用插值补全\n",
    "    return df_comp\n",
    "\n",
    "def create_subtable(set_table_dict):\n",
    "    set_subtable_dic_fun = {}  #set_subtable_dic_fun数据组织形式 {'table_A_2':set_subtable_linktable_dic_fun,\n",
    "                               #                            'table_A_3':set_subtable_linktable_dic_fun, ...}}\n",
    "    for i in range(len(inter_toll)):\n",
    "        inter, toll = inter_toll[i]\n",
    "        tableName = 'table_'+str(inter)+'_'+str(toll)\n",
    "        set_subtable_linktable_dic_fun = {} #嵌套在set_subtable_fun中的dic\n",
    "        for linkOrder in range(LINK_LENGTH[tableName]):\n",
    "            print('inter = ',inter,'\\n','toll=',toll,'\\n','linkOrder=',linkOrder,'\\n')\n",
    "            linktable_name = tableName + '_link_' + str(linkOrder)\n",
    "            set_subtable_linktable_dic_fun[linktable_name] = set_table_dict[tableName].loc[:,\\\n",
    "                                                                                            ['intersection_id',\\\n",
    "                                                                                            'tollgate_id',\\\n",
    "                                                                                            'starting_time',\\\n",
    "                                                                                            'link_'+str(linkOrder)]]\n",
    "            #groupby子表\n",
    "            set_subtable_linktable_dic_fun[linktable_name] = set_subtable_linktable_dic_fun\\\n",
    "            [linktable_name].groupby(['intersection_id', 'tollgate_id', 'starting_time']).median() #取中值可能更好\n",
    "            set_subtable_linktable_dic_fun[linktable_name] = set_subtable_linktable_dic_fun\\\n",
    "            [linktable_name].reset_index()\n",
    "            \n",
    "            #complete_miss_time\n",
    "            set_subtable_linktable_dic_fun[linktable_name] = \\\n",
    "            complete_miss_time(set_subtable_linktable_dic_fun[linktable_name],\\\n",
    "                               inter, toll, 'link_'+str(linkOrder), df_type = 'train')\n",
    "            \n",
    "        set_subtable_dic_fun[tableName] = set_subtable_linktable_dic_fun\n",
    "    return set_subtable_dic_fun\n",
    "\n",
    "#每个link和inter, toll, starting_time单独成一个子表，各自groupby后，进行compleme_miss_time，再合并回一个table\n",
    "def groupbyProcess(set_table_dict):\n",
    "    #每个link和inter, toll, starting_time单独成一个子表\n",
    "    set_subtable_dic = create_subtable(set_table_dict) #输出正确\n",
    "\n",
    "    return set_subtable_dic       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('inter = ', 'A', '\\n', 'toll=', 2, '\\n', 'linkOrder=', 0, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 2, '\\n', 'linkOrder=', 1, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 2, '\\n', 'linkOrder=', 2, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 2, '\\n', 'linkOrder=', 3, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 2, '\\n', 'linkOrder=', 4, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 2, '\\n', 'linkOrder=', 5, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 0, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 1, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 2, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 3, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 4, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 5, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 6, '\\n')\n",
      "('inter = ', 'A', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 7, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 0, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 1, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 2, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 3, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 4, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 5, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 6, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 7, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 8, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 0, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 1, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 2, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 3, '\\n')\n",
      "('inter = ', 'B', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 4, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 0, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 1, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 2, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 3, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 4, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 5, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 6, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 7, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 8, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 9, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 10, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 1, '\\n', 'linkOrder=', 11, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 0, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 1, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 2, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 3, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 4, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 5, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 6, '\\n')\n",
      "('inter = ', 'C', '\\n', 'toll=', 3, '\\n', 'linkOrder=', 7, '\\n')\n"
     ]
    }
   ],
   "source": [
    "#取出相同路段的avgTime，并groupby求平均;然后interpolate\n",
    "set_table_dict_afterGroupby = groupbyProcess(set_table_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#合并子表\n",
    "def combineSubtable(set_table_dict_afterGroupby):\n",
    "    set_table_combine_dict_fun = {}\n",
    "    for i in range(len(inter_toll)):\n",
    "        inter, toll = inter_toll[i]\n",
    "        tableName = 'table_'+str(inter)+'_'+str(toll)\n",
    "        subtable_name = tableName + '_link_'+str(0)\n",
    "        set_table_combine_dict_fun[tableName] = set_table_dict_afterGroupby[tableName][subtable_name].copy()\n",
    "        for linkOrder in range(1,LINK_LENGTH[tableName]):\n",
    "            linkname = 'link_'+str(linkOrder)\n",
    "            subtable_name = tableName + '_link_'+str(linkOrder)\n",
    "            set_table_combine_dict_fun[tableName][linkname] = set_table_dict_afterGroupby[tableName][subtable_name]\\\n",
    "                                                                [linkname] #取列，插到新表的后面\n",
    "#     print(set_table_combine_dict_fun['table_A_2'])\n",
    "    return set_table_combine_dict_fun\n",
    "set_table_combine_dict = combineSubtable(set_table_dict_afterGroupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2136, 9)\n",
      "0\n",
      "(2136, 11)\n",
      "0\n",
      "(2136, 12)\n",
      "0\n",
      "(2136, 8)\n",
      "0\n",
      "(2136, 15)\n",
      "0\n",
      "(2136, 11)\n",
      "8904\n",
      "   intersection_id  tollgate_id       starting_time   link_0   link_1  \\\n",
      "0                C            3 2016-07-19 06:00:00      NaN      NaN   \n",
      "1                C            3 2016-07-19 06:20:00     8.34    10.11   \n",
      "2                C            3 2016-07-19 06:40:00     8.67     8.08   \n",
      "3                C            3 2016-07-19 07:00:00     4.75     5.81   \n",
      "4                C            3 2016-07-19 07:20:00      7.3      7.7   \n",
      "5                C            3 2016-07-19 07:40:00      NaN      NaN   \n",
      "6                C            3 2016-07-19 08:00:00     6.14     7.52   \n",
      "7                C            3 2016-07-19 08:20:00     9.62    10.85   \n",
      "8                C            3 2016-07-19 08:40:00      NaN      NaN   \n",
      "9                C            3 2016-07-19 09:00:00      NaN      NaN   \n",
      "10               C            3 2016-07-19 09:20:00      NaN      NaN   \n",
      "11               C            3 2016-07-19 09:40:00     8.33     7.99   \n",
      "12               C            3 2016-07-19 15:00:00    10.54     9.63   \n",
      "13               C            3 2016-07-19 15:20:00  9.92667     9.77   \n",
      "14               C            3 2016-07-19 15:40:00      NaN      NaN   \n",
      "15               C            3 2016-07-19 16:00:00    10.72   12.475   \n",
      "16               C            3 2016-07-19 16:20:00  9.50667  9.63667   \n",
      "17               C            3 2016-07-19 16:40:00    10.31     8.99   \n",
      "18               C            3 2016-07-19 17:00:00     6.59     6.66   \n",
      "19               C            3 2016-07-19 17:20:00  8.99333  10.1067   \n",
      "20               C            3 2016-07-19 17:40:00       10     8.98   \n",
      "21               C            3 2016-07-19 18:00:00     6.18     8.25   \n",
      "22               C            3 2016-07-19 18:20:00  13.2233    11.08   \n",
      "23               C            3 2016-07-19 18:40:00    11.04    11.61   \n",
      "24               C            3 2016-07-20 06:00:00      NaN      NaN   \n",
      "25               C            3 2016-07-20 06:20:00      NaN      NaN   \n",
      "26               C            3 2016-07-20 06:40:00      NaN      NaN   \n",
      "27               C            3 2016-07-20 07:00:00    38.58     9.97   \n",
      "28               C            3 2016-07-20 07:20:00   11.655   13.745   \n",
      "29               C            3 2016-07-20 07:40:00    13.26     9.28   \n",
      "\n",
      "     link_2   link_3   link_4   link_5   link_6   link_7  \n",
      "0       NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "1       9.9    22.04    18.81    14.52     3.38    71.74  \n",
      "2      7.49    16.44    15.97   141.36     0.98    24.81  \n",
      "3      5.99    12.99     8.82    85.33     1.16     9.92  \n",
      "4      9.32    26.23    57.27     94.4     2.63    30.12  \n",
      "5       NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "6     13.99    32.32    21.95    13.35     2.54    21.73  \n",
      "7     10.79    23.42    16.34    33.33     6.85    30.37  \n",
      "8       NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "9       NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "10      NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "11     7.68    21.03    14.09    51.66     1.99     25.7  \n",
      "12     9.01    20.18    17.18    57.73     1.81     29.1  \n",
      "13  9.42667  26.4133    41.93  33.7433  29.2033  23.5067  \n",
      "14      NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "15    11.52   31.045   27.225    54.52     4.01    29.57  \n",
      "16  10.6533  37.4933    27.17  39.3233     9.67    98.85  \n",
      "17     8.92    20.69    14.64    10.79     2.08     18.5  \n",
      "18     6.37    15.86    12.76    16.18     1.73    32.09  \n",
      "19  10.2467  20.2433  32.4433  57.3167  2.06667    29.78  \n",
      "20     7.88    23.35    72.62    46.52     1.12    31.77  \n",
      "21     8.19    40.75    24.14     15.9     6.93    22.43  \n",
      "22  9.67667    25.29  78.8133  79.6233     2.25  32.3467  \n",
      "23    11.97    25.36     67.8    11.57      2.7    32.96  \n",
      "24      NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "25      NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "26      NaN      NaN      NaN      NaN      NaN      NaN  \n",
      "27    10.28    41.32    33.17    20.17     5.02    59.97  \n",
      "28    14.11   30.625   20.795    32.71     2.64   296.79  \n",
      "29     9.56       23    21.39    61.53     2.32    33.09  \n"
     ]
    }
   ],
   "source": [
    "a = set_table_combine_dict['table_B_1']\n",
    "for inter,toll in inter_toll:\n",
    "    tableName = 'table_'+str(inter)+'_'+str(toll)\n",
    "    a = set_table_combine_dict[tableName]\n",
    "    print(a.shape)\n",
    "    print(a.isnull().sum().sum())\n",
    "print(set_table_combine_dict['table_C_3'].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "[[ 1  2  3  4]\n",
      " [ 4  5  6  7]\n",
      " [ 7  8  9 10]]\n",
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 7  8]\n",
      " [ 9 10]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],[4,5,6,7],[7,8,9,10]])\n",
    "print(a.shape)\n",
    "print(a)\n",
    "print(a.reshape(6,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
